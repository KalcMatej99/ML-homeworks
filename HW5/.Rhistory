contains95CI <- vector(mode="list", length = 10000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
contains95CI[j] <- FALSE
if((true_risk < (as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j]))) && (true_risk > as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j]))) {
contains95CI[j] <- TRUE
}
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 10000)
est_se <- vector(mode="list", length = 10000)
contains95CI <- vector(mode="list", length = 10000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
contains95CI[j] <- FALSE
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
if(true_risk < upper_bound_CI && true_risk > lower_bound_CI) {
contains95CI[j] <- TRUE
}
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 10000)
est_se <- vector(mode="list", length = 10000)
contains95CI <- vector(mode="list", length = 10000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
contains95CI[j] <- FALSE
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <-true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 10000)
est_se <- vector(mode="list", length = 10000)
contains95CI <- vector(mode="list", length = 10000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
differences_between_true_and_est_risk <- as.numeric(est_risk) - true_risk
differences_between_true_and_est_risk <- as.numeric(est_risk) - true_risk
differences_between_true_and_est_risk <- est_risk - true_risk
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
print(true_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
print(true_risk)
print(as.numeric(est_risk))
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk")
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk")
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("0.5-0.5 baseline true risk: %f", true_risk_5050)
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("0.5-0.5 baseline true risk: %f", true_risk_5050)
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("0.5-0.5 baseline true risk: %f", true_risk_5050)
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
print(contains95CI)
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
print(true_risk < upper_bound_CI && true_risk > lower_bound_CI)
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
print(upper_bound_CI)
print(lower_bound_CI)
print(true_risk < upper_bound_CI && true_risk > lower_bound_CI)
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se[j] <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
print(upper_bound_CI)
print(lower_bound_CI)
print(true_risk < upper_bound_CI && true_risk > lower_bound_CI)
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se[j] <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n, 0)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se[j] <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
print(true_risk)
print(est_risk)
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
set.seed(0)
library(stats)
#install.packages("ggplot2", lib="/usr/share/R/library")
library(ggplot2, lib.loc="/usr/share/R/library")
#install.packages("dplyr", lib="/usr/share/R/library")
library(dplyr)
#install.packages(c("base64enc", "evaluate", "highr", "htmltools", "jsonlite", "knitr", "markdown", "mime", "rmarkdown", "stringi", "stringr", "xfun", "yaml"), lib="/usr/share/R/library")
toy_data <- function(n, seed = NULL) {
set.seed(seed)
x <- matrix(rnorm(8 * n), ncol = 8)
z <- 0.4 * x[,1] - 0.5 * x[,2] + 1.75 * x[,3] - 0.2 * x[,4] + x[,5]
y <- runif(n) > 1 / (1 + exp(-z))
return (data.frame(x = x, y = y))
}
log_loss <- function(y, p) {
-(y * log(p) + (1 - y) * log(1 - p))
}
df_huge <- toy_data(100000, 0)
n <- 50
df_dgp <- toy_data(n, 0)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(log_loss(y, glm.probs))
true_risk_5050 <- mean(log_loss(y, 0.5))
est_risk <- vector(mode="list", length = 10000)
est_se <- vector(mode="list", length = 10000)
contains95CI <- vector(mode="list", length = 10000)
for(j in 1:10000) {
n <- 50
df_dgp <- toy_data(n)
y <- df_dgp$y
X <- df_dgp[, seq(1, 8)]
glm.probs <- predict(glm.fit, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se[j] <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
differences_between_true_and_est_risk <- as.numeric(est_risk) - true_risk
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk")
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("0.5-0.5 baseline true risk: %f", true_risk_5050)
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
n <- 50
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
diff_risk1_risk2 <- vector(mode="list", length = 50)
for(j in 1:50) {
df_dgp1 <- toy_data(n)
glm.fit1 <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp1, family="binomial")
df_dgp2 <- rbind(df_dgp1, toy_data(n))
glm.fit2 <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp2, family="binomial")
glm.probs1 <- predict(glm.fit1, newdata = X, type = "response")
glm.probs2 <- predict(glm.fit2, newdata = X, type = "response")
true_risk_1 <- mean(as.numeric(log_loss(y, glm.probs1)))
true_risk_2 <- mean(as.numeric(log_loss(y, glm.probs2)))
diff_risk1_risk2[j] <- true_risk_1 - true_risk_2
}
summary(as.numeric(diff_risk1_risk2))
n <- 100
y <- df_huge$y
X <- df_huge[, seq(1, 8)]
df_dgp <- toy_data(n, 0)
glm.fit <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=df_dgp, family="binomial")
glm.probs <- predict(glm.fit, newdata = X, type = "response")
true_risk <- mean(as.numeric(log_loss(y, glm.probs)))
print(true_risk)
est_risk <- vector(mode="list", length = 1000)
est_se <- vector(mode="list", length = 1000)
contains95CI <- vector(mode="list", length = 1000)
for(j in 1:1000) {
split_dummy <- sample(c(rep(0, 0.5 * nrow(df_dgp)),  # Create dummy for splitting
rep(1, 0.5 * nrow(df_dgp))))
data_train <- df_dgp[split_dummy == 0, ]
data_test <- df_dgp[split_dummy == 1, ]
glm.fit_h <- glm(y ~ x.1 + x.2 + x.3+ x.4 + x.5+ x.6 + x.7+ x.8, data=data_train, family="binomial")
y <- data_test$y
X <- data_test[, seq(1, 8)]
glm.probs <- predict(glm.fit_h, newdata = X, type = "response")
losses <- log_loss(y, glm.probs)
est_risk[j] <- mean(as.numeric(losses))
est_se[j] <- sd(as.numeric(unlist(losses)))/sqrt(length(losses))
upper_bound_CI <- as.numeric(est_risk[j]) + 1.96 * as.numeric(est_se[j])
lower_bound_CI <- as.numeric(est_risk[j]) - 1.96 * as.numeric(est_se[j])
contains95CI[j] <- true_risk < upper_bound_CI && true_risk > lower_bound_CI
}
differences_between_true_and_est_risk <- as.numeric(est_risk) - as.numeric(true_risk)
df_dens <- data.frame(differences_between_true_and_est_risk)
colnames(df_dens) <- c("x")
plot(ggplot(data = df_dens, aes(x = x)) +
geom_density() + labs(title = "Density",
caption = "Density of estimated risk - true risk") +
xlab("est_risk - true_risk"))
sprintf("True risk proxy: %f", as.numeric(true_risk))
sprintf("Mean difference: %f", mean(differences_between_true_and_est_risk))
sprintf("Median standard error: %f", median(as.numeric(est_se)))
sprintf("Percentage of 95CI that contain the true risk proxy: %f", mean(as.numeric(contains95CI)))
install.packages("stringi", lib="/usr/share/R/library")
